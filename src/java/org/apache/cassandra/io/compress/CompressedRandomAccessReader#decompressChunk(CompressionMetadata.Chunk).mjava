    private void decompressChunk(CompressionMetadata.Chunk chunk) throws IOException
    {
        if (channel.position() != chunk.offset)
            channel.position(chunk.offset);

        if (compressed.capacity() < chunk.length)
            compressed = ByteBuffer.wrap(new byte[chunk.length]);
        else
            compressed.clear();
        compressed.limit(chunk.length);

        if (channel.read(compressed) != chunk.length)
            throw new CorruptBlockException(getPath(), chunk);

        // technically flip() is unnecessary since all the remaining work uses the raw array, but if that changes
        // in the future this will save a lot of hair-pulling
        compressed.flip();

        // If the checksum is on compressed data we want to check it before uncompressing the data
        if (metadata.hasPostCompressionAdlerChecksums)
            checkChecksumIfNeeded(chunk, compressed.array(), chunk.length);

        try
        {
            validBufferBytes = metadata.compressor().uncompress(compressed.array(), 0, chunk.length, buffer, 0);
        }
        catch (IOException e)
        {
            throw new CorruptBlockException(getPath(), chunk, e);
        }

        if (!metadata.hasPostCompressionAdlerChecksums)
            checkChecksumIfNeeded(chunk, buffer, validBufferBytes);


        // buffer offset is always aligned
        bufferOffset = current & ~(buffer.length - 1);
        // the length() can be provided at construction time, to override the true (uncompressed) length of the file;
        // this is permitted to occur within a compressed segment, so we truncate validBufferBytes if we cross the imposed length
        if (bufferOffset + validBufferBytes > length())
            validBufferBytes = (int)(length() - bufferOffset);
    }

