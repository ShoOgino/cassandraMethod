        public void run()
        {
            // mark writes older than the barrier as blocking progress, permitting them to exceed our memory limit
            // if they are stuck waiting on it, then wait for them all to complete
            writeBarrier.markBlocking();
            writeBarrier.await();

            // mark all memtables as flushing, removing them from the live memtable list, and
            // remove any memtables that are already clean from the set we need to flush
            Iterator<Memtable> iter = memtables.iterator();
            while (iter.hasNext())
            {
                Memtable memtable = iter.next();
                memtable.cfs.data.markFlushing(memtable);
                if (memtable.isClean() || truncate)
                {
                    memtable.cfs.replaceFlushed(memtable, null);
                    reclaim(memtable);
                    iter.remove();
                }
            }

            if (memtables.isEmpty())
            {
                postFlush.latch.countDown();
                return;
            }

            metric.memtableSwitchCount.inc();

            try
            {
                for (Memtable memtable : memtables)
                {
                    // flush the memtable
                    MoreExecutors.sameThreadExecutor().execute(memtable.flushRunnable());
                    reclaim(memtable);
                }

                // signal the post-flush we've done our work
                // Note: This should not be done in case of error. Read more below.
                postFlush.latch.countDown();
            }
            catch (FSWriteError e)
            {
                JVMStabilityInspector.inspectThrowable(e);
                // The call above may kill the process or the transports, or ignore the error.
                // In any case we should not be passing on control to post-flush as a subsequent succeeding flush
                // could mask the error and:
                //   - let the commit log discard unpersisted data, resulting in data loss
                //   - let truncations proceed, with the possibility of resurrecting the unflushed data
                //   - let snapshots succeed with incomplete data

                // Not passing control on means that all flushes from the moment of failure cannot complete
                // (including snapshots).
                // If the disk failure policy is ignore, this will cause memtables and the commit log to grow
                // unboundedly until the node eventually fails.
                previousFlushFailure = e;
                throw e;
            }
        }

