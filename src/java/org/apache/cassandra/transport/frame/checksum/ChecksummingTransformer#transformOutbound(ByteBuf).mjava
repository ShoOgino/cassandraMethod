    public ByteBuf transformOutbound(ByteBuf inputBuf)
    {
        // be pessimistic about life and assume the compressed output will be the same size as the input bytes
        int maxTotalCompressedLength = maxCompressedLength(inputBuf.readableBytes());
        int expectedChunks = (int) Math.ceil((double) maxTotalCompressedLength / blockSize);
        int expectedMaxSerializedLength = Short.BYTES + (expectedChunks * CHUNK_HEADER_OVERHEAD) + maxTotalCompressedLength;
        byte[] retBuf = new byte[expectedMaxSerializedLength];
        ByteBuf ret = Unpooled.wrappedBuffer(retBuf);
        ret.writerIndex(0);
        ret.readerIndex(0);

        // write out bogus short to start with as we'll encode one at the end
        // when we finalize the number of compressed chunks to expect and this
        // sets the writer index correctly for starting the first chunk
        ret.writeShort((short) 0);

        byte[] inBuf = new byte[blockSize];
        byte[] outBuf = new byte[maxCompressedLength(blockSize)];
        byte[] chunkLengths = new byte[8];

        int numCompressedChunks = 0;
        int readableBytes;
        int lengthsChecksum;
        while ((readableBytes = inputBuf.readableBytes()) > 0)
        {
            int lengthToRead = Math.min(blockSize, readableBytes);
            inputBuf.readBytes(inBuf, 0, lengthToRead);
            int uncompressedChunkChecksum = (int) checksum.of(inBuf, 0, lengthToRead);
            int compressedSize = maybeCompress(inBuf, lengthToRead, outBuf);

            if (compressedSize < lengthToRead)
            {
                // there was some benefit to compression so write out the compressed
                // and uncompressed sizes of the chunk
                ret.writeInt(compressedSize);
                ret.writeInt(lengthToRead);
                putInt(compressedSize, chunkLengths, 0);
            }
            else
            {
                // if no compression was possible, there's no need to write two lengths, so
                // just write the size of the original content (or block size), with its
                // sign flipped to signal no compression.
                ret.writeInt(-lengthToRead);
                putInt(-lengthToRead, chunkLengths, 0);
            }

            putInt(lengthToRead, chunkLengths, 4);

            // calculate the checksum of the compressed and decompressed lengths
            // protect us against a bogus length causing potential havoc on deserialization
            lengthsChecksum = (int) checksum.of(chunkLengths, 0, chunkLengths.length);
            ret.writeInt(lengthsChecksum);

            // figure out how many actual bytes we're going to write and make sure we have capacity
            int toWrite = Math.min(compressedSize, lengthToRead);
            if (ret.writableBytes() < (CHUNK_HEADER_OVERHEAD + toWrite))
            {
                // this really shouldn't ever happen -- it means we either mis-calculated the number of chunks we
                // expected to create, we gave some input to the compressor that caused the output to be much
                // larger than the input.. or some other edge condition. Regardless -- resize if necessary.
                byte[] resizedRetBuf = new byte[(retBuf.length + (CHUNK_HEADER_OVERHEAD + toWrite)) * 3 / 2];
                System.arraycopy(retBuf, 0, resizedRetBuf, 0, retBuf.length);
                retBuf = resizedRetBuf;
                ByteBuf resizedRetByteBuf = Unpooled.wrappedBuffer(retBuf);
                resizedRetByteBuf.writerIndex(ret.writerIndex());
                ret = resizedRetByteBuf;
            }

            // write the bytes, either compressed or uncompressed
            if (compressedSize < lengthToRead)
                ret.writeBytes(outBuf, 0, toWrite); // compressed
            else
                ret.writeBytes(inBuf, 0, toWrite);  // uncompressed

            // checksum of the uncompressed chunk
            ret.writeInt(uncompressedChunkChecksum);

            numCompressedChunks++;
        }

        // now update the number of chunks
        ret.setShort(0, (short) numCompressedChunks);
        return ret;
    }

