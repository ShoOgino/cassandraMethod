    public AbstractCompactionTask getNextBackgroundTask(final int gcBefore)
    {
        if (cfs.isCompactionDisabled())
        {
            logger.debug("Compaction is currently disabled.");
            return null;
        }

        Set<SSTableReader> candidates = cfs.getUncompactingSSTables();
        List<List<SSTableReader>> buckets = getBuckets(createSSTableAndLengthPairs(filterSuspectSSTables(candidates)), minSSTableSize);
        updateEstimatedCompactionsByTasks(buckets);

        List<List<SSTableReader>> prunedBuckets = new ArrayList<List<SSTableReader>>();
        for (List<SSTableReader> bucket : buckets)
        {
            if (bucket.size() < cfs.getMinimumCompactionThreshold())
                continue;

            Collections.sort(bucket, new Comparator<SSTableReader>()
            {
                public int compare(SSTableReader o1, SSTableReader o2)
                {
                    return o1.descriptor.generation - o2.descriptor.generation;
                }
            });
            prunedBuckets.add(bucket.subList(0, Math.min(bucket.size(), cfs.getMaximumCompactionThreshold())));
        }

        if (prunedBuckets.isEmpty())
        {
            // if there is no sstable to compact in standard way, try compacting single sstable whose droppable tombstone
            // ratio is greater than threshold.
            for (List<SSTableReader> bucket : buckets)
            {
                for (SSTableReader table : bucket)
                {
                    double droppableRatio = table.getEstimatedDroppableTombstoneRatio(gcBefore);
                    if (droppableRatio <= tombstoneThreshold)
                        continue;

                    Set<SSTableReader> overlaps = cfs.getOverlappingSSTables(Collections.singleton(table));
                    if (overlaps.isEmpty())
                    {
                        // there is no overlap, tombstones are safely droppable
                        prunedBuckets.add(Collections.singletonList(table));
                    }
                    else
                    {
                        // what percentage of columns do we expect to compact outside of overlap?
                        // first, calculate estimated keys that do not overlap
                        long keys = table.estimatedKeys();
                        Set<Range<Token>> ranges = new HashSet<Range<Token>>();
                        for (SSTableReader overlap : overlaps)
                            ranges.add(new Range<Token>(overlap.first.token, overlap.last.token));
                        long remainingKeys = keys - table.estimatedKeysForRanges(ranges);
                        // next, calculate what percentage of columns we have within those keys
                        double remainingKeysRatio = ((double) remainingKeys) / keys;
                        long columns = table.getEstimatedColumnCount().percentile(remainingKeysRatio) * remainingKeys;
                        double remainingColumnsRatio = ((double) columns) / (table.getEstimatedColumnCount().count() * table.getEstimatedColumnCount().mean());

                        // if we still expect to have droppable tombstones in rest of columns, then try compacting it
                        if (remainingColumnsRatio * droppableRatio > tombstoneThreshold)
                            prunedBuckets.add(Collections.singletonList(table));
                    }
                }
            }

            if (prunedBuckets.isEmpty())
                return null;
        }

        List<SSTableReader> smallestBucket = Collections.min(prunedBuckets, new Comparator<List<SSTableReader>>()
        {
            public int compare(List<SSTableReader> o1, List<SSTableReader> o2)
            {
                long n = avgSize(o1) - avgSize(o2);
                if (n < 0)
                    return -1;
                if (n > 0)
                    return 1;
                return 0;
            }

            private long avgSize(List<SSTableReader> sstables)
            {
                long n = 0;
                for (SSTableReader sstable : sstables)
                    n += sstable.bytesOnDisk();
                return n / sstables.size();
            }
        });
        // when bucket only contains just one sstable, set userDefined to true to force single sstable compaction
        return new CompactionTask(cfs, smallestBucket, gcBefore).isUserDefined(smallestBucket.size() == 1);
    }

